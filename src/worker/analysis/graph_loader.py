"""
Graph-RAG v2: Neo4j ê·¸ë˜í”„ ë¹Œë”

Tree-sitter íŒŒì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œë¥¼ ASTë¡œ íŒŒì‹±í•˜ê³ 
Neo4j ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ì— ì ì¬

Features:
- Tree-sitter ê¸°ë°˜ AST íŒŒì‹± (Python, JavaScript, TypeScript, Java, Go)
- JSONL ìŠ¤í…Œì´ì§• (EFS/ë¡œì»¬ ì €ì¥ì†Œ)
- Neo4j ëŒ€ëŸ‰ ì ì¬ (Cypher UNWIND)
- ì»¤ë°‹ í•´ì‹œ ê¸°ë°˜ ìŠ¤ëƒ…ìƒ· ìºì‹±
"""
import os
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timezone
from uuid import UUID

try:
    from tree_sitter import Language, Parser
    import tree_sitter_python as tspython
    import tree_sitter_javascript as tsjavascript
    TREE_SITTER_AVAILABLE = True
except ImportError:
    TREE_SITTER_AVAILABLE = False

from neo4j import GraphDatabase
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Shared ëª¨ë¸ import
from shared.graph_models import GraphSnapshot


class GraphLoader:
    """
    Neo4j ê·¸ë˜í”„ ì ì¬ ë° ë²„ì „ ê´€ë¦¬

    Workflow:
    1. parse_with_tree_sitter() - AST ì¶”ì¶œ
    2. stage_to_jsonl() - EFS/ë¡œì»¬ì— JSONL ì €ì¥
    3. bulk_load_to_neo4j() - Neo4jì— ëŒ€ëŸ‰ ì ì¬
    4. create_snapshot() - PostgreSQLì— ìŠ¤ëƒ…ìƒ· ê¸°ë¡
    """

    # ì§€ì› ì–¸ì–´ ë§¤í•‘
    LANGUAGE_PARSERS = {
        '.py': 'python',
        '.js': 'javascript',
        '.jsx': 'javascript',
        '.ts': 'typescript',
        '.tsx': 'typescript',
        '.java': 'java',
        '.go': 'go',
    }

    def __init__(
        self,
        neo4j_uri: str,
        neo4j_user: str,
        neo4j_password: str,
        postgres_url: str,
        staging_dir: str = "/tmp/graph_staging"
    ):
        """
        Args:
            neo4j_uri: Neo4j ì—°ê²° URI (bolt://...)
            neo4j_user: Neo4j ì‚¬ìš©ìëª…
            neo4j_password: Neo4j ë¹„ë°€ë²ˆí˜¸
            postgres_url: PostgreSQL ì—°ê²° URL (ìŠ¤ëƒ…ìƒ· ì €ì¥ìš©)
            staging_dir: JSONL ìŠ¤í…Œì´ì§• ë””ë ‰í† ë¦¬
        """
        if not TREE_SITTER_AVAILABLE:
            raise RuntimeError(
                "Tree-sitter not installed. "
                "Install with: pip install tree-sitter tree-sitter-languages"
            )

        self.neo4j_driver = GraphDatabase.driver(
            neo4j_uri,
            auth=(neo4j_user, neo4j_password)
        )

        # PostgreSQL ì„¸ì…˜ (ìŠ¤ëƒ…ìƒ· ê´€ë¦¬)
        engine = create_engine(postgres_url)
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
        self.db = SessionLocal()

        self.staging_dir = Path(staging_dir)
        self.staging_dir.mkdir(parents=True, exist_ok=True)

        # Tree-sitter íŒŒì„œ ì´ˆê¸°í™”
        self._init_parsers()

    def _init_parsers(self):
        """Tree-sitter ì–¸ì–´ íŒŒì„œ ì´ˆê¸°í™”"""
        self.parsers = {}

        # Python íŒŒì„œ
        PY_LANGUAGE = Language(tspython.language())
        py_parser = Parser(PY_LANGUAGE)
        self.parsers['python'] = py_parser

        # JavaScript/TypeScript íŒŒì„œ
        JS_LANGUAGE = Language(tsjavascript.language())
        js_parser = Parser(JS_LANGUAGE)
        self.parsers['javascript'] = js_parser
        self.parsers['typescript'] = js_parser  # ë™ì¼ íŒŒì„œ ì‚¬ìš©

        print("âœ… Tree-sitter parsers initialized: python, javascript, typescript")

    def parse_with_tree_sitter(
        self,
        repo_path: str,
        file_extensions: Optional[List[str]] = None
    ) -> Tuple[List[Dict], List[Dict]]:
        """
        Tree-sitterë¡œ ì €ì¥ì†Œì˜ ëª¨ë“  íŒŒì¼ íŒŒì‹±

        Args:
            repo_path: Git ì €ì¥ì†Œ ê²½ë¡œ
            file_extensions: íŒŒì‹±í•  íŒŒì¼ í™•ì¥ì (Noneì´ë©´ ëª¨ë“  ì§€ì› ì–¸ì–´)

        Returns:
            (nodes, edges): ë…¸ë“œ ë¦¬ìŠ¤íŠ¸, ì—£ì§€ ë¦¬ìŠ¤íŠ¸
        """
        if file_extensions is None:
            file_extensions = list(self.LANGUAGE_PARSERS.keys())

        nodes = []
        edges = []
        file_count = 0

        repo_root = Path(repo_path)
        print(f"ğŸ” Parsing repository: {repo_root}")

        for ext in file_extensions:
            if ext not in self.LANGUAGE_PARSERS:
                print(f"âš ï¸  Unsupported extension: {ext}")
                continue

            language = self.LANGUAGE_PARSERS[ext]
            parser = self.parsers.get(language)

            if not parser:
                print(f"âš ï¸  No parser for language: {language}")
                continue

            # í•´ë‹¹ í™•ì¥ì íŒŒì¼ ì°¾ê¸°
            pattern = f"**/*{ext}"
            for file_path in repo_root.glob(pattern):
                if self._should_skip_file(file_path):
                    continue

                file_nodes, file_edges = self._parse_file(file_path, parser, language, repo_root)
                nodes.extend(file_nodes)
                edges.extend(file_edges)
                file_count += 1

                if file_count % 50 == 0:
                    print(f"  ğŸ“„ Parsed {file_count} files ({len(nodes)} nodes, {len(edges)} edges)...")

        print(f"âœ… Parsing complete: {file_count} files â†’ {len(nodes)} nodes, {len(edges)} edges")
        return nodes, edges

    def _should_skip_file(self, file_path: Path) -> bool:
        """íŒŒì¼ ìŠ¤í‚µ ì—¬ë¶€ ê²°ì •"""
        skip_dirs = {'node_modules', '.git', '__pycache__', 'venv', 'dist', 'build'}
        return any(part in skip_dirs for part in file_path.parts)

    def _parse_file(
        self,
        file_path: Path,
        parser: Parser,
        language: str,
        repo_root: Path
    ) -> Tuple[List[Dict], List[Dict]]:
        """
        ë‹¨ì¼ íŒŒì¼ íŒŒì‹± (Tree-sitter)

        Returns:
            (file_nodes, file_edges)
        """
        try:
            with open(file_path, 'rb') as f:
                source_code = f.read()

            tree = parser.parse(source_code)
            root_node = tree.root_node

            # íŒŒì¼ ë…¸ë“œ ìƒì„±
            rel_path = str(file_path.relative_to(repo_root))
            file_node = {
                "id": f"file:{rel_path}",
                "type": "File",
                "path": rel_path,
                "language": language,
                "loc": source_code.count(b'\n') + 1
            }

            nodes = [file_node]
            edges = []

            # í•¨ìˆ˜/í´ë˜ìŠ¤ ë…¸ë“œ ì¶”ì¶œ
            if language == 'python':
                func_nodes, class_nodes, func_edges = self._extract_python_symbols(
                    root_node, source_code, rel_path
                )
                nodes.extend(func_nodes)
                nodes.extend(class_nodes)
                edges.extend(func_edges)

            elif language in ['javascript', 'typescript']:
                func_nodes, class_nodes, func_edges = self._extract_js_symbols(
                    root_node, source_code, rel_path
                )
                nodes.extend(func_nodes)
                nodes.extend(class_nodes)
                edges.extend(func_edges)

            return nodes, edges

        except Exception as e:
            print(f"âš ï¸  Failed to parse {file_path}: {e}")
            return [], []

    def _extract_python_symbols(
        self,
        root_node,
        source_code: bytes,
        file_path: str
    ) -> Tuple[List[Dict], List[Dict], List[Dict]]:
        """Python ASTì—ì„œ í•¨ìˆ˜/í´ë˜ìŠ¤ ì¶”ì¶œ"""
        functions = []
        classes = []
        edges = []

        # ì¬ê·€ì ìœ¼ë¡œ AST íƒìƒ‰
        def traverse(node):
            if node.type == 'function_definition':
                func_name_node = node.child_by_field_name('name')
                if func_name_node:
                    func_name = source_code[func_name_node.start_byte:func_name_node.end_byte].decode('utf-8')
                    func_id = f"func:{file_path}:{func_name}"

                    functions.append({
                        "id": func_id,
                        "type": "Function",
                        "name": func_name,
                        "file_path": file_path,
                        "start_line": node.start_point[0] + 1,
                        "end_line": node.end_point[0] + 1
                    })

                    # File â†’ Function ì—£ì§€
                    edges.append({
                        "from_id": f"file:{file_path}",
                        "to_id": func_id,
                        "type": "CONTAINS"
                    })

            elif node.type == 'class_definition':
                class_name_node = node.child_by_field_name('name')
                if class_name_node:
                    class_name = source_code[class_name_node.start_byte:class_name_node.end_byte].decode('utf-8')
                    class_id = f"class:{file_path}:{class_name}"

                    classes.append({
                        "id": class_id,
                        "type": "Class",
                        "name": class_name,
                        "file_path": file_path,
                        "start_line": node.start_point[0] + 1
                    })

                    # File â†’ Class ì—£ì§€
                    edges.append({
                        "from_id": f"file:{file_path}",
                        "to_id": class_id,
                        "type": "CONTAINS"
                    })

            # ìì‹ ë…¸ë“œ íƒìƒ‰
            for child in node.children:
                traverse(child)

        traverse(root_node)
        return functions, classes, edges

    def _extract_js_symbols(
        self,
        root_node,
        source_code: bytes,
        file_path: str
    ) -> Tuple[List[Dict], List[Dict], List[Dict]]:
        """JavaScript/TypeScript ASTì—ì„œ í•¨ìˆ˜/í´ë˜ìŠ¤ ì¶”ì¶œ"""
        # Pythonê³¼ ìœ ì‚¬í•œ ë¡œì§ (ê°„ëµí™”)
        # ì‹¤ì œë¡œëŠ” 'function_declaration', 'arrow_function', 'class_declaration' ë“± ì²˜ë¦¬
        functions = []
        classes = []
        edges = []

        # TODO: JS/TS ì „ìš© íŒŒì‹± ë¡œì§ êµ¬í˜„
        # í˜„ì¬ëŠ” ê¸°ë³¸ êµ¬ì¡°ë§Œ ì œê³µ

        return functions, classes, edges

    def stage_to_jsonl(
        self,
        nodes: List[Dict],
        edges: List[Dict],
        analysis_id: str
    ) -> Tuple[str, str]:
        """
        JSONL íŒŒì¼ë¡œ ìŠ¤í…Œì´ì§•

        Args:
            nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
            edges: ì—£ì§€ ë¦¬ìŠ¤íŠ¸
            analysis_id: ë¶„ì„ ì‘ì—… ID

        Returns:
            (nodes_file, edges_file): JSONL íŒŒì¼ ê²½ë¡œ
        """
        analysis_dir = self.staging_dir / analysis_id
        analysis_dir.mkdir(parents=True, exist_ok=True)

        nodes_file = analysis_dir / "graph_nodes.jsonl"
        edges_file = analysis_dir / "graph_edges.jsonl"

        # ë…¸ë“œ JSONL ì €ì¥
        with open(nodes_file, 'w') as f:
            for node in nodes:
                f.write(json.dumps(node) + '\n')

        # ì—£ì§€ JSONL ì €ì¥
        with open(edges_file, 'w') as f:
            for edge in edges:
                f.write(json.dumps(edge) + '\n')

        print(f"âœ… JSONL staged: {nodes_file} ({len(nodes)} nodes)")
        print(f"âœ… JSONL staged: {edges_file} ({len(edges)} edges)")

        return str(nodes_file), str(edges_file)

    def bulk_load_to_neo4j(
        self,
        nodes_file: str,
        edges_file: str,
        batch_size: int = 1000
    ) -> Tuple[int, int]:
        """
        Neo4jì— ëŒ€ëŸ‰ ì ì¬ (Cypher UNWIND)

        Args:
            nodes_file: ë…¸ë“œ JSONL íŒŒì¼ ê²½ë¡œ
            edges_file: ì—£ì§€ JSONL íŒŒì¼ ê²½ë¡œ
            batch_size: ë°°ì¹˜ í¬ê¸°

        Returns:
            (nodes_created, edges_created)
        """
        start_time = time.time()

        # ë…¸ë“œ ì ì¬
        with open(nodes_file, 'r') as f:
            nodes = [json.loads(line) for line in f]

        nodes_created = self._create_nodes_batch(nodes, batch_size)

        # ì—£ì§€ ì ì¬
        with open(edges_file, 'r') as f:
            edges = [json.loads(line) for line in f]

        edges_created = self._create_edges_batch(edges, batch_size)

        elapsed = time.time() - start_time
        print(f"âœ… Neo4j bulk load complete: {nodes_created} nodes, {edges_created} edges ({elapsed:.2f}s)")

        return nodes_created, edges_created

    def _create_nodes_batch(self, nodes: List[Dict], batch_size: int) -> int:
        """ë…¸ë“œ ë°°ì¹˜ ìƒì„± (Cypher UNWIND)"""
        total_created = 0

        with self.neo4j_driver.session() as session:
            for i in range(0, len(nodes), batch_size):
                batch = nodes[i:i + batch_size]

                # íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”
                nodes_by_type = {}
                for node in batch:
                    node_type = node.get('type', 'Unknown')
                    if node_type not in nodes_by_type:
                        nodes_by_type[node_type] = []
                    nodes_by_type[node_type].append(node)

                # íƒ€ì…ë³„ UNWIND ì¿¼ë¦¬ ì‹¤í–‰
                for node_type, typed_nodes in nodes_by_type.items():
                    query = f"""
                    UNWIND $nodes AS node
                    CREATE (n:{node_type})
                    SET n = node
                    """
                    result = session.run(query, nodes=typed_nodes)
                    total_created += len(typed_nodes)

                if (i + batch_size) % 5000 == 0:
                    print(f"  ğŸ“Š Created {total_created}/{len(nodes)} nodes...")

        return total_created

    def _create_edges_batch(self, edges: List[Dict], batch_size: int) -> int:
        """ì—£ì§€ ë°°ì¹˜ ìƒì„± (Cypher UNWIND)"""
        total_created = 0

        with self.neo4j_driver.session() as session:
            for i in range(0, len(edges), batch_size):
                batch = edges[i:i + batch_size]

                # ê´€ê³„ íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”
                edges_by_type = {}
                for edge in batch:
                    edge_type = edge.get('type', 'RELATED_TO')
                    if edge_type not in edges_by_type:
                        edges_by_type[edge_type] = []
                    edges_by_type[edge_type].append(edge)

                # íƒ€ì…ë³„ UNWIND ì¿¼ë¦¬ ì‹¤í–‰
                for edge_type, typed_edges in edges_by_type.items():
                    query = f"""
                    UNWIND $edges AS edge
                    MATCH (from {{id: edge.from_id}})
                    MATCH (to {{id: edge.to_id}})
                    CREATE (from)-[r:{edge_type}]->(to)
                    SET r.properties = COALESCE(edge.properties, {{}})
                    """
                    result = session.run(query, edges=typed_edges)
                    total_created += len(typed_edges)

                if (i + batch_size) % 5000 == 0:
                    print(f"  ğŸ“Š Created {total_created}/{len(edges)} edges...")

        return total_created

    def create_snapshot(
        self,
        analysis_id: UUID,
        commit_hash: str,
        repo_url: str,
        node_count: int,
        edge_count: int,
        node_types: Dict[str, int],
        build_duration: int,
        branch: str = "main"
    ) -> str:
        """
        PostgreSQLì— ê·¸ë˜í”„ ìŠ¤ëƒ…ìƒ· ê¸°ë¡

        Returns:
            snapshot_id (str)
        """
        snapshot = GraphSnapshot(
            analysis_id=analysis_id,
            commit_hash=commit_hash,
            repo_url=repo_url,
            branch=branch,
            node_count=node_count,
            edge_count=edge_count,
            node_types=node_types,
            build_duration_seconds=build_duration,
            is_valid=True
        )

        self.db.add(snapshot)
        self.db.commit()
        self.db.refresh(snapshot)

        print(f"âœ… Snapshot created: {snapshot.id} (commit: {commit_hash[:8]})")
        return str(snapshot.id)

    def reuse_snapshot(self, commit_hash: str) -> Optional[str]:
        """
        ì»¤ë°‹ í•´ì‹œ ê¸°ë°˜ ìŠ¤ëƒ…ìƒ· ì¬ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

        Returns:
            snapshot_id (str) ë˜ëŠ” None
        """
        snapshot = self.db.query(GraphSnapshot).filter(
            GraphSnapshot.commit_hash == commit_hash,
            GraphSnapshot.is_valid == True
        ).first()

        if snapshot:
            print(f"âœ… Reusing existing snapshot: {snapshot.id} (commit: {commit_hash[:8]})")
            return str(snapshot.id)

        print(f"â„¹ï¸  No snapshot found for commit: {commit_hash[:8]}")
        return None

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.neo4j_driver.close()
        self.db.close()

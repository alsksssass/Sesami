# ë¡œì»¬ ê°œë°œ í™˜ê²½ êµ¬ì¶• ê°€ì´ë“œ

## ğŸ¯ ëª©í‘œ

ë¡œì»¬ Docker Compose í™˜ê²½ì—ì„œ ì „ì²´ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•˜ì—¬:
- âœ… í•µì‹¬ ë¶„ì„ ë¡œì§ 100% ì™„ì„±
- âœ… API ê¸°ëŠ¥ ê²€ì¦
- âœ… Frontend-Backend í†µí•© í…ŒìŠ¤íŠ¸
- âœ… AWS ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„

---

## ğŸ“‹ ì‚¬ì „ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´
```bash
# ë²„ì „ í™•ì¸
docker --version          # Docker 20.10+
docker-compose --version  # Docker Compose 2.0+
node --version            # Node.js 18+
python --version          # Python 3.12+
git --version             # Git 2.30+
```

### GitHub OAuth ì•± ì„¤ì •
1. GitHub Settings â†’ Developer settings â†’ OAuth Apps â†’ New OAuth App
2. ì„¤ì •:
   - **Application name**: `Sesami Local Dev`
   - **Homepage URL**: `http://localhost:3000`
   - **Authorization callback URL**: `http://localhost:3000/auth/callback`
3. ìƒì„± í›„ **Client ID**ì™€ **Client Secret** ì €ì¥

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í”„ë¡œì íŠ¸ í´ë¡ 
```bash
cd ~/goinfre
git clone <repository-url> Sesami
cd Sesami
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„± (ì´ë¯¸ ì¡´ì¬í•  ìˆ˜ ìˆìŒ)
cat > .env << 'EOF'
# Database
POSTGRES_USER=sesami_user
POSTGRES_PASSWORD=sesami_password_2025
POSTGRES_DB=sesami_db
DB_PORT=5432
DATABASE_URL=postgresql://sesami_user:sesami_password_2025@db:5432/sesami_db

# Redis
REDIS_HOST=queue
REDIS_PORT=6379
REDIS_EXTERNAL_PORT=6379
QUEUE_BROKER_URL=redis://queue:6379/0

# Application Ports
FRONTEND_PORT=3000
BACKEND_PORT=8000
BACKEND_HOST=0.0.0.0

# URLs
FRONTEND_URL=http://localhost:3000
BACKEND_URL=http://localhost:8000

# GitHub OAuth (âš ï¸ ì‹¤ì œ ê°’ìœ¼ë¡œ êµì²´ í•„ìš”)
GITHUB_CLIENT_ID=your_github_client_id_here
GITHUB_CLIENT_SECRET=your_github_client_secret_here
GITHUB_REDIRECT_URI=http://localhost:3000/auth/callback

# JWT Security
JWT_SECRET_KEY=your-super-secret-jwt-key-change-this-in-production-256-bit-minimum
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=15
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# Encryption
ENCRYPTION_KEY=your-fernet-encryption-key-base64-encoded-here

# Task Service (ë¡œì»¬ í™˜ê²½)
TASK_SERVICE_IMPL=LOCAL

# Worker
CELERY_BROKER_URL=redis://queue:6379/0
CELERY_RESULT_BACKEND=redis://queue:6379/0

# Logging
LOG_LEVEL=INFO
EOF
```

### 3. ì•”í˜¸í™” í‚¤ ìƒì„±
```bash
# Pythonìœ¼ë¡œ Fernet í‚¤ ìƒì„±
python3 << 'EOF'
from cryptography.fernet import Fernet
key = Fernet.generate_key()
print(f"ENCRYPTION_KEY={key.decode()}")
EOF

# ì¶œë ¥ëœ í‚¤ë¥¼ .env íŒŒì¼ì˜ ENCRYPTION_KEYì— ë³µì‚¬
```

### 4. ì „ì²´ ì‹œìŠ¤í…œ ì‹¤í–‰
```bash
# Docker Composeë¡œ ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up --build

# ë˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
docker-compose up -d --build

# ë¡œê·¸ í™•ì¸
docker-compose logs -f
```

### 5. ì ‘ì† í™•ì¸
```bash
# Frontend
open http://localhost:3000

# Backend API ë¬¸ì„œ
open http://localhost:8000/docs

# PostgreSQL (ì™¸ë¶€ í´ë¼ì´ì–¸íŠ¸)
psql postgresql://sesami_user:sesami_password_2025@localhost:5432/sesami_db

# Redis (redis-cli)
redis-cli -h localhost -p 6379
```

---

## ğŸ—ï¸ ì„œë¹„ìŠ¤ë³„ ìƒì„¸ ì„¤ëª…

### Frontend (React + Vite)

**Docker ì„¤ì •** (`docker/frontend/Dockerfile`):
```dockerfile
FROM node:20-alpine

WORKDIR /app

# ì˜ì¡´ì„± ì„¤ì¹˜ ìµœì í™”
COPY src/frontend/package*.json ./
RUN npm ci

# ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬
COPY src/frontend/ ./

# ê°œë°œ ì„œë²„ ì‹¤í–‰
EXPOSE 3000
CMD ["npm", "run", "dev", "--", "--host", "0.0.0.0"]
```

**ì£¼ìš” íŒŒì¼**:
- `src/frontend/src/App.tsx` - ë¼ìš°íŒ… ë° ë ˆì´ì•„ì›ƒ
- `src/frontend/src/contexts/AuthContext.tsx` - ì¸ì¦ ìƒíƒœ ê´€ë¦¬
- `src/frontend/src/pages/` - í˜ì´ì§€ ì»´í¬ë„ŒíŠ¸
- `src/frontend/src/services/` - API í´ë¼ì´ì–¸íŠ¸

**ë¡œì»¬ ê°œë°œ**:
```bash
# Frontend ì»¨í…Œì´ë„ˆ ì‰˜ ì ‘ì†
docker-compose exec frontend sh

# ì˜ì¡´ì„± ì¶”ê°€
npm install <package-name>

# ë¹Œë“œ í™•ì¸
npm run build
```

---

### Backend (FastAPI)

**Docker ì„¤ì •** (`docker/backend/Dockerfile`):
```dockerfile
FROM python:3.12-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„±
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„±
COPY src/backend/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì†ŒìŠ¤ ì½”ë“œ
COPY src/backend/ ./

# ê°œë°œ ì„œë²„ (hot reload)
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

**ì£¼ìš” ë””ë ‰í† ë¦¬ êµ¬ì¡°**:
```
src/backend/
â”œâ”€â”€ main.py                    # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”œâ”€â”€ config.py                  # ì„¤ì • ê´€ë¦¬ (pydantic-settings)
â”œâ”€â”€ common/                    # ê³µí†µ ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ database.py           # SQLAlchemy ì„¸ì…˜ ê´€ë¦¬
â”‚   â”œâ”€â”€ dependencies.py       # FastAPI ì˜ì¡´ì„± ì£¼ì…
â”‚   â”œâ”€â”€ encryption.py         # Fernet ì•”í˜¸í™”
â”‚   â”œâ”€â”€ exceptions.py         # ì»¤ìŠ¤í…€ ì˜ˆì™¸
â”‚   â””â”€â”€ task_service/         # TaskService ì¶”ìƒí™”
â”‚       â”œâ”€â”€ base.py           # ITaskService ì¸í„°í˜ì´ìŠ¤
â”‚       â””â”€â”€ local_service.py  # LocalTaskService (Celery)
â”œâ”€â”€ features/
â”‚   â””â”€â”€ v1/
â”‚       â”œâ”€â”€ auth/             # ì¸ì¦ ëª¨ë“ˆ
â”‚       â”‚   â”œâ”€â”€ api.py        # ë¼ìš°í„°
â”‚       â”‚   â”œâ”€â”€ models.py     # SQLAlchemy ëª¨ë¸
â”‚       â”‚   â”œâ”€â”€ schemas.py    # Pydantic ìŠ¤í‚¤ë§ˆ
â”‚       â”‚   â”œâ”€â”€ github_service.py
â”‚       â”‚   â””â”€â”€ jwt_service.py
â”‚       â””â”€â”€ github_analysis/  # ë¶„ì„ ëª¨ë“ˆ
â”‚           â”œâ”€â”€ api.py
â”‚           â”œâ”€â”€ models.py
â”‚           â”œâ”€â”€ schemas.py
â”‚           â””â”€â”€ services/
â”‚               â”œâ”€â”€ analysis_service.py
â”‚               â””â”€â”€ github_api_service.py
```

**ë¡œì»¬ ê°œë°œ**:
```bash
# Backend ì»¨í…Œì´ë„ˆ ì‰˜ ì ‘ì†
docker-compose exec backend bash

# ì˜ì¡´ì„± ì¶”ê°€
pip install <package-name>
# requirements.txt ì—…ë°ì´íŠ¸
pip freeze > requirements.txt

# ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
alembic revision --autogenerate -m "migration message"
alembic upgrade head

# ëŒ€í™”í˜• Python (DB ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸)
python
>>> from common.database import SessionLocal
>>> db = SessionLocal()
>>> # ì¿¼ë¦¬ ì‹¤í–‰
```

---

### Worker (Celery)

**Docker ì„¤ì •** (`docker/worker/Dockerfile`):
```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Git í•„ìˆ˜ (ë ˆí¬ì§€í† ë¦¬ í´ë¡ )
RUN apt-get update && apt-get install -y \
    git \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„±
COPY src/worker/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì†ŒìŠ¤ ì½”ë“œ
COPY src/worker/ ./

# Celery Worker ì‹¤í–‰
CMD ["celery", "-A", "celery_app", "worker", "--loglevel=info"]
```

**ì£¼ìš” íŒŒì¼**:
```
src/worker/
â”œâ”€â”€ celery_app.py             # Celery ì•± ì´ˆê¸°í™”
â”œâ”€â”€ tasks.py                  # Celery íƒœìŠ¤í¬ ì •ì˜
â”œâ”€â”€ database.py               # SQLAlchemy (Workerìš©)
â””â”€â”€ analysis/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ git_analyzer.py       # Git ë¶„ì„ ë¡œì§ (âš ï¸ êµ¬í˜„ í•„ìš”)
```

**í•µì‹¬ êµ¬í˜„ í•„ìš”: `git_analyzer.py`**

```python
# src/worker/analysis/git_analyzer.py

import os
import tempfile
import subprocess
from typing import Dict, List
from git import Repo
from collections import defaultdict

class GitAnalyzer:
    """Git ì €ì¥ì†Œ ë¶„ì„ ì—”ì§„"""

    def __init__(self, repo_url: str, access_token: str):
        self.repo_url = repo_url
        self.access_token = access_token
        self.temp_dir = None
        self.repo = None

    def clone_repository(self) -> str:
        """Private ì €ì¥ì†Œ í´ë¡  (Access Token ì‚¬ìš©)"""
        self.temp_dir = tempfile.mkdtemp(prefix='sesami_analysis_')

        # https://oauth2:TOKEN@github.com/user/repo.git í˜•ì‹
        auth_url = self.repo_url.replace(
            'https://',
            f'https://oauth2:{self.access_token}@'
        )

        self.repo = Repo.clone_from(auth_url, self.temp_dir)
        return self.temp_dir

    def analyze_blame(self, user_email: str) -> Dict[str, float]:
        """git blameìœ¼ë¡œ ì‚¬ìš©ì ê¸°ì—¬ë„ ë¶„ì„"""
        if not self.repo:
            raise ValueError("Repository not cloned")

        user_lines = 0
        total_lines = 0

        # ëª¨ë“  ì¶”ì ëœ íŒŒì¼ ìˆœíšŒ
        for item in self.repo.tree().traverse():
            if item.type == 'blob':  # íŒŒì¼ë§Œ
                file_path = item.path

                try:
                    # git blame ì‹¤í–‰
                    blame = self.repo.git.blame(
                        '--line-porcelain',
                        'HEAD',
                        '--',
                        file_path
                    )

                    for line in blame.split('\n'):
                        if line.startswith('author-mail'):
                            email = line.split('<')[1].split('>')[0]
                            total_lines += 1
                            if email == user_email:
                                user_lines += 1

                except Exception as e:
                    # ë°”ì´ë„ˆë¦¬ íŒŒì¼ ë“± blame ë¶ˆê°€ëŠ¥í•œ íŒŒì¼ ìŠ¤í‚µ
                    continue

        contribution_rate = (user_lines / total_lines * 100) if total_lines > 0 else 0

        return {
            'user_lines': user_lines,
            'total_lines': total_lines,
            'contribution_percentage': round(contribution_rate, 2)
        }

    def analyze_tech_stack(self) -> Dict[str, any]:
        """íŒŒì¼ í™•ì¥ì ë° í”„ë ˆì„ì›Œí¬ ë¶„ì„"""
        if not self.repo:
            raise ValueError("Repository not cloned")

        extensions = defaultdict(int)
        frameworks = set()

        for item in self.repo.tree().traverse():
            if item.type == 'blob':
                # í™•ì¥ì ì¹´ìš´íŠ¸
                _, ext = os.path.splitext(item.path)
                if ext:
                    extensions[ext] += 1

                # í”„ë ˆì„ì›Œí¬ ê°ì§€ íŒŒì¼
                filename = os.path.basename(item.path)
                if filename == 'package.json':
                    frameworks.add('Node.js/npm')
                elif filename == 'requirements.txt':
                    frameworks.add('Python')
                elif filename == 'pom.xml':
                    frameworks.add('Java/Maven')
                elif filename == 'Dockerfile':
                    frameworks.add('Docker')

        return {
            'languages': dict(extensions),
            'frameworks': list(frameworks)
        }

    def cleanup(self):
        """ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            subprocess.run(['rm', '-rf', self.temp_dir])
```

**ë¡œì»¬ í…ŒìŠ¤íŠ¸**:
```bash
# Worker ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
docker-compose logs -f worker

# Celery ì‘ì—… í ìƒíƒœ
docker-compose exec worker celery -A celery_app inspect active

# ìˆ˜ë™ ì‘ì—… íŠ¸ë¦¬ê±° (Python shell)
docker-compose exec backend python
>>> from common.task_service.local_service import LocalTaskService
>>> svc = LocalTaskService()
>>> svc.submit_analysis_job(user_id="test", repo_url="https://github.com/user/repo")
```

---

## ğŸ§ª ê°œë°œ ì›Œí¬í”Œë¡œìš°

### 1. ìƒˆë¡œìš´ ê¸°ëŠ¥ ê°œë°œ
```bash
# 1. Feature ë¸Œëœì¹˜ ìƒì„±
git checkout -b feature/new-analysis-metric

# 2. ì½”ë“œ ì‘ì„±
# Backend: src/backend/features/v1/...
# Frontend: src/frontend/src/...
# Worker: src/worker/analysis/...

# 3. ë¡œì»¬ í…ŒìŠ¤íŠ¸
docker-compose up -d
# ë¸Œë¼ìš°ì €ì—ì„œ í…ŒìŠ¤íŠ¸

# 4. ë¡œê·¸ í™•ì¸
docker-compose logs -f backend
docker-compose logs -f worker

# 5. ì»¤ë°‹ ë° í‘¸ì‹œ
git add .
git commit -m "feat: add new analysis metric"
git push origin feature/new-analysis-metric
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë³€ê²½
```bash
# 1. SQLAlchemy ëª¨ë¸ ìˆ˜ì •
# src/backend/features/v1/*/models.py

# 2. ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±
docker-compose exec backend alembic revision --autogenerate -m "add analysis_results table"

# 3. ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©
docker-compose exec backend alembic upgrade head

# 4. ë¡¤ë°± (í•„ìš”ì‹œ)
docker-compose exec backend alembic downgrade -1
```

### 3. API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
```python
# src/backend/features/v1/github_analysis/api.py

from fastapi import APIRouter, Depends
from common.dependencies import get_current_user
from .schemas import AnalysisRequest, AnalysisResponse
from .services.analysis_service import AnalysisService

router = APIRouter(prefix="/api/v1/analysis", tags=["analysis"])

@router.post("/start", response_model=AnalysisResponse)
async def start_analysis(
    request: AnalysisRequest,
    current_user = Depends(get_current_user),
    service: AnalysisService = Depends()
):
    """ìƒˆë¡œìš´ ë¶„ì„ ì‘ì—… ì‹œì‘"""
    result = await service.create_analysis_job(
        user_id=current_user.id,
        repo_url=request.repo_url
    )
    return result
```

### 4. ë¬¸ì œ í•´ê²°

**ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘**:
```bash
# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì¬ì‹œì‘
docker-compose restart backend

# ì „ì²´ ì¬ì‹œì‘
docker-compose restart

# ìºì‹œ ë¬´íš¨í™” í›„ ì¬ë¹Œë“œ
docker-compose down
docker-compose up --build --force-recreate
```

**ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”**:
```bash
# âš ï¸ ëª¨ë“  ë°ì´í„° ì‚­ì œ ì£¼ì˜
docker-compose down -v
docker-compose up -d
```

**í¬íŠ¸ ì¶©ëŒ í•´ê²°**:
```bash
# í¬íŠ¸ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ í™•ì¸
lsof -i :3000
lsof -i :8000
lsof -i :5432

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>
```

---

## ğŸ“ ê°œë°œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Backend ê°œë°œ
- [ ] API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- [ ] Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜
- [ ] SQLAlchemy ëª¨ë¸ ìƒì„±
- [ ] ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„œë¹„ìŠ¤ ê³„ì¸µ êµ¬í˜„
- [ ] ì˜ì¡´ì„± ì£¼ì… ì„¤ì •
- [ ] ì˜ˆì™¸ ì²˜ë¦¬ ë° ì—ëŸ¬ í•¸ë“¤ë§
- [ ] API ë¬¸ì„œ (FastAPI ìë™ ìƒì„±)
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (pytest)

### Frontend ê°œë°œ
- [ ] í˜ì´ì§€ ì»´í¬ë„ŒíŠ¸ ìƒì„±
- [ ] API ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸
- [ ] ìƒíƒœ ê´€ë¦¬ (Context API)
- [ ] ë¼ìš°íŒ… ì„¤ì •
- [ ] UI/UX ë””ìì¸ (Tailwind CSS)
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ë¡œë”© ìƒíƒœ
- [ ] ë°˜ì‘í˜• ë””ìì¸
- [ ] íƒ€ì… ì•ˆì •ì„± (TypeScript)

### Worker ê°œë°œ
- [ ] Celery íƒœìŠ¤í¬ ì •ì˜
- [ ] Git ë¶„ì„ ë¡œì§ êµ¬í˜„
- [ ] ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„
- [ ] ê²°ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
- [ ] ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
- [ ] ì„±ëŠ¥ ìµœì í™” (ëŒ€ìš©ëŸ‰ ë ˆí¬ì§€í† ë¦¬)

---

**ë‹¤ìŒ ë¬¸ì„œ**: [03_AWS_MIGRATION.md](./03_AWS_MIGRATION.md) - AWS í”„ë¡œë•ì…˜ í™˜ê²½ ë§ˆì´ê·¸ë ˆì´ì…˜

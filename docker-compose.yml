# ====================================================================
# Sesami PDD v4.0 - Docker Compose Configuration
# ====================================================================
#
# Architecture:
#   L1: Backend API + Main Orchestrator (FastAPI)
#   L2: Sub Orchestrator (로컬: Celery, AWS: Step Functions)
#   L3: Batch Jobs (L3-Tools, L3-Builders, L3-Agents)
#
# 로컬 개발 환경에서는 Celery Chain으로 L1/L2/L3를 시뮬레이션합니다.
# AWS 환경에서는 Step Functions + AWS Batch로 대체됩니다.
# ====================================================================

networks:
  analyzer-net:
    driver: bridge

# ====================================================================
# 서비스 정의
# ====================================================================
services:
  # ==================================================================
  # L1: Backend API + Main Orchestrator (FastAPI)
  # ==================================================================
  backend:
    build:
      context: .
      dockerfile: ./docker/backend/Dockerfile
    command: uvicorn main:app --host ${BACKEND_HOST} --port ${BACKEND_PORT} --reload
    ports:
      - "${BACKEND_PORT}:${BACKEND_PORT}"
    volumes:
      - ./src/backend:/app
      - ./src/shared:/app/shared  # Event Envelope 스키마 공유
      - efs_mock:/mnt/efs  # L2 결과 저장용 (AWS EFS 시뮬레이션)
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - QUEUE_BROKER_URL=${QUEUE_BROKER_URL}
      - FRONTEND_URL=${FRONTEND_URL}
      - TASK_SERVICE_IMPL=${TASK_SERVICE_IMPL:-LOCAL}
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - OPENSEARCH_ENDPOINT=${OPENSEARCH_ENDPOINT}
      - OPENSEARCH_USER=${OPENSEARCH_USER}
      - OPENSEARCH_PASSWORD=${OPENSEARCH_PASSWORD}
      - EFS_MOUNT_PATH=/mnt/efs
      - PYTHONPATH=/app
    env_file:
      - .env
    networks:
      - analyzer-net
    depends_on:
      db:
        condition: service_healthy
      queue:
        condition: service_started
      neo4j:
        condition: service_healthy
      opensearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:${BACKEND_PORT}/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 20s

  # ==================================================================
  # L2: Sub Orchestrator (로컬: Celery Worker)
  # ==================================================================
  # 역할:
  #   1. L3-Tool Fan-out (100%)
  #   2. Filter (CPU)
  #   3. L3-Agent Fan-out (10%)
  #   4. Reduce (EFS에 L2 요약본 저장)
  # ==================================================================
  l2-orchestrator:
    build:
      context: .
      dockerfile: ./docker/worker/Dockerfile
    command: celery -A celery_app worker --loglevel=info --concurrency=4 -Q l2_orchestrator
    volumes:
      - ./src/worker:/app
      - ./src/shared:/app/shared
      - ./src/backend/common:/app/common  # Backend common 모듈 접근
      - ./src/backend/config.py:/app/backend_config.py  # Backend config.py 접근
      - efs_mock:/mnt/efs  # L2 Reducer가 요약본 저장
    working_dir: /app
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - QUEUE_BROKER_URL=${QUEUE_BROKER_URL}
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - OPENSEARCH_ENDPOINT=${OPENSEARCH_ENDPOINT}
      - OPENSEARCH_USER=${OPENSEARCH_USER}
      - OPENSEARCH_PASSWORD=${OPENSEARCH_PASSWORD}
      - EFS_MOUNT_PATH=/mnt/efs
      - WORKER_TYPE=L2_ORCHESTRATOR
      - PYTHONPATH=/app
    env_file:
      - .env
    networks:
      - analyzer-net
    depends_on:
      db:
        condition: service_healthy
      queue:
        condition: service_started
      neo4j:
        condition: service_healthy
      opensearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "celery -A celery_app inspect ping || exit 1"] 
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ==================================================================
  # L3-Tools: 저비용 CPU 기반 분석 (100% 실행)
  # ==================================================================
  # 특징:
  #   - Graviton 호환 (ARM64)
  #   - 결정론적 (같은 입력 → 같은 출력)
  #   - Event Envelope 반환
  # 도구:
  #   - Pylint (Python 품질)
  #   - SonarQube (코드 복잡도)
  #   - Semgrep (보안 패턴)
  #   - TruffleHog (시크릿 스캔)
  #   - DORA Calculator (변경 빈도)
  # ==================================================================
  l3-tools:
    build:
      context: .
      dockerfile: ./docker/worker/Dockerfile.l3tools
      args:
        - BUILDPLATFORM=linux/amd64  # 로컬: x86, AWS: linux/arm64 (Graviton)
    command: celery -A celery_app worker --loglevel=info --concurrency=10 -Q l3_tools
    volumes:
      - ./src/worker:/app
      - ./src/shared:/app/shared  # Event Envelope 스키마 공유
      - ./src/backend/common:/app/common  # Backend common 모듈 접근
      - ./src/backend/config.py:/app/backend_config.py  # Backend config.py 접근
      - efs_mock:/mnt/efs  # L3 결과 저장
    working_dir: /app
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - QUEUE_BROKER_URL=${QUEUE_BROKER_URL}
      - EFS_MOUNT_PATH=/mnt/efs
      - WORKER_TYPE=L3_TOOLS
      - PYLINT_RCFILE=/app/.pylintrc
      - SONAR_HOST_URL=${SONAR_HOST_URL:-http://sonarqube:9000}
      - SEMGREP_RULES=p/security-audit,p/secrets
      - TRUFFLEHOG_VERIFY=true
      - PYTHONPATH=/app
    env_file:
      - .env
    networks:
      - analyzer-net
    depends_on:
      - queue
    deploy:
      resources:
        limits:
          cpus: '2'  # CPU 집약적
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "celery -A celery_app inspect ping || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ==================================================================
  # L3-Builders: 그래프/벡터 DB 구축 (1회 실행)
  # ==================================================================
  # 특징:
  #   - 저장소당 1회만 실행
  #   - Tree-sitter 파싱 → Neo4j 적재
  #   - Bedrock 임베딩 → OpenSearch 인덱싱
  # 빌더:
  #   - Graph Builder (graph_loader.py)
  #   - Vector Builder (semantic_search.py)
  # ==================================================================
  l3-builders:
    build:
      context: .
      dockerfile: ./docker/worker/Dockerfile.l3builders
    command: celery -A celery_app worker --loglevel=info --concurrency=2 -Q l3_builders
    volumes:
      - ./src/worker:/app
      - ./src/shared:/app/shared  # Event Envelope 스키마 공유
      - ./src/backend/common:/app/common  # Backend common 모듈 접근
      - ./src/backend/config.py:/app/backend_config.py  # Backend config.py 접근
      - efs_mock:/mnt/efs  # 저장소 클론 + JSONL 스테이징
    working_dir: /app
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - QUEUE_BROKER_URL=${QUEUE_BROKER_URL}
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - OPENSEARCH_ENDPOINT=${OPENSEARCH_ENDPOINT}
      - OPENSEARCH_USER=${OPENSEARCH_USER}
      - OPENSEARCH_PASSWORD=${OPENSEARCH_PASSWORD}
      - AWS_REGION=${AWS_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - USE_BEDROCK=${USE_BEDROCK}
      - BEDROCK_EMBEDDING_MODEL_ID=${BEDROCK_EMBEDDING_MODEL_ID}
      - BEDROCK_MODEL_ID=${BEDROCK_MODEL_ID:-amazon.titan-embed-text-v1}
      - EFS_MOUNT_PATH=/mnt/efs
      - WORKER_TYPE=L3_BUILDERS
      - PYTHONPATH=/app
    env_file:
      - .env
    networks:
      - analyzer-net
    depends_on:
      - queue
      - neo4j
      - opensearch
    deploy:
      resources:
        limits:
          cpus: '4'  # 파싱 + 임베딩 생성
          memory: 8G
    healthcheck:
      test: ["CMD-SHELL", "celery -A celery_app inspect ping || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ==================================================================
  # L3-Agents: 고비용 LLM 기반 분석 (10% 선별 실행)
  # ==================================================================
  # 특징:
  #   - LLM 사용 (Bedrock Claude 3.5 Sonnet)
  #   - Graph-RAG + Vector-RAG 도구 활용
  #   - L2-Filter 통과한 유의미한 파일만 분석
  # 에이전트:
  #   - Proficiency Agent (숙련도 평가)
  #   - Architecture Agent (아키텍처 분석)
  #   - Collaboration Agent (협업 패턴 분석)
  # ==================================================================
  l3-agents:
    build:
      context: .
      dockerfile: ./docker/worker/Dockerfile.l3agents
    command: celery -A celery_app worker --loglevel=info --concurrency=2 -Q l3_agents
    volumes:
      - ./src/worker:/app
      - ./src/shared:/app/shared  # Event Envelope 스키마 공유
      - ./src/backend/common:/app/common  # Backend common 모듈 접근
      - ./src/backend/config.py:/app/backend_config.py  # Backend config.py 접근
      - efs_mock:/mnt/efs  # L3 결과 읽기/쓰기
    working_dir: /app
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - QUEUE_BROKER_URL=${QUEUE_BROKER_URL}
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - OPENSEARCH_ENDPOINT=${OPENSEARCH_ENDPOINT}
      - OPENSEARCH_USER=${OPENSEARCH_USER}
      - OPENSEARCH_PASSWORD=${OPENSEARCH_PASSWORD}
      - AWS_REGION=${AWS_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - USE_BEDROCK=${USE_BEDROCK}
      - BEDROCK_LLM_MODEL_ID=${BEDROCK_LLM_MODEL_ID}
      - BEDROCK_MODEL_ID=${BEDROCK_MODEL_ID:-anthropic.claude-3-5-sonnet-20241022-v2:0}
      - EFS_MOUNT_PATH=/mnt/efs
      - WORKER_TYPE=L3_AGENTS
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE}
      - PYTHONPATH=/app
    env_file:
      - .env
    networks:
      - analyzer-net
    depends_on:
      - queue
      - neo4j
      - opensearch
    deploy:
      resources:
        limits:
          cpus: '2'  # LLM 호출 대기 시간 많음
          memory: 4G
    healthcheck:
      test: ["CMD-SHELL", "celery -A celery_app inspect ping || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ==================================================================
  # Infrastructure Services
  # ==================================================================

  # PostgreSQL 데이터베이스 (분석 메타데이터, 사용자 정보)
  db:
    build:
      context: .
      dockerfile: ./docker/db/Dockerfile
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    env_file:
      - .env
    ports:
      - "${DB_PORT}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - analyzer-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Redis 작업 큐 (로컬 개발용, AWS: SQS로 대체)
  queue:
    build:
      context: .
      dockerfile: ./docker/queue/Dockerfile
    ports:
      - "${REDIS_EXTERNAL_PORT}:${REDIS_PORT}"
    env_file:
      - .env
    networks:
      - analyzer-net
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s

  # Neo4j 그래프 데이터베이스 (코드 구조 저장)
  neo4j:
    image: neo4j:5.15-community
    container_name: sesami-neo4j
    environment:
      - NEO4J_AUTH=${NEO4J_USER}/${NEO4J_PASSWORD}
      - NEO4J_PLUGINS=["apoc","graph-data-science"]
      - NEO4J_dbms_memory_heap_max__size=2G
      - NEO4J_dbms_memory_pagecache_size=1G
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*
      - NEO4J_dbms_security_procedures_allowlist=apoc.*,gds.*
      - NEO4J_server_bolt_listen__address=0.0.0.0:7687
      - NEO4J_server_http_listen__address=0.0.0.0:7474
    ports:
      - "7474:7474"  # HTTP (Neo4j Browser)
      - "7687:7687"  # Bolt Protocol
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - efs_mock:/import  # JSONL 스테이징 파일 임포트용
    networks:
      - analyzer-net
    healthcheck:
      test: ["CMD-SHELL", "cypher-shell -u ${NEO4J_USER} -p ${NEO4J_PASSWORD} 'RETURN 1' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # OpenSearch 벡터 스토어 (시맨틱 코드 검색)
  opensearch:
    image: opensearchproject/opensearch:2.11.0
    container_name: sesami-opensearch
    environment:
      - discovery.type=single-node
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_PASSWORD}
      - DISABLE_SECURITY_PLUGIN=false
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - plugins.security.ssl.http.enabled=true
      - plugins.security.ssl.transport.enabled=true
    ports:
      - "${OPENSEARCH_PORT}:9200"  # REST API
      - "${OPENSEARCH_PERF_PORT}:9600"  # Performance Analyzer
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    networks:
      - analyzer-net
    env_file:
      - .env
    healthcheck:
      test: ["CMD-SHELL", "curl -k -u ${OPENSEARCH_USER}:${OPENSEARCH_PASSWORD} https://localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

# ====================================================================
# 영속성 볼륨
# ====================================================================
volumes:
  postgres_data:
    driver: local
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  opensearch_data:
    driver: local
  efs_mock:
    driver: local
    # AWS EFS 시뮬레이션:
    #   - L3 작업자가 결과를 /mnt/efs/{analysis_id}/l3_results/ 에 저장
    #   - L2 Reducer가 /mnt/efs/{analysis_id}/l2_summaries/ 에 저장
    #   - L1 Finalize가 /mnt/efs/{analysis_id}/l1_reports/ 에 저장
    # AWS 환경에서는 실제 EFS 마운트로 대체
